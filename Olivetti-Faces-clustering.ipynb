{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11aa228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /Users/maryam/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "##Load the dataset using the sklearn.datasets.fetch_olivetti_faces()\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "dataset = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fba5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _olivetti_faces_dataset:\n",
      "\n",
      "The Olivetti faces dataset\n",
      "--------------------------\n",
      "\n",
      "`This dataset contains a set of face images`_ taken between April 1992 and \n",
      "April 1994 at AT&T Laboratories Cambridge. The\n",
      ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
      "fetching / caching function that downloads the data\n",
      "archive from AT&T.\n",
      "\n",
      ".. _This dataset contains a set of face images: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "\n",
      "As described on the original website:\n",
      "\n",
      "    There are ten different images of each of 40 distinct subjects. For some\n",
      "    subjects, the images were taken at different times, varying the lighting,\n",
      "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "    details (glasses / no glasses). All the images were taken against a dark\n",
      "    homogeneous background with the subjects in an upright, frontal position \n",
      "    (with tolerance for some side movement).\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =====================\n",
      "    Classes                                40\n",
      "    Samples total                         400\n",
      "    Dimensionality                       4096\n",
      "    Features            real, between 0 and 1\n",
      "    =================   =====================\n",
      "\n",
      "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
      "integers; the loader will convert these to floating point values on the \n",
      "interval [0, 1], which are easier to work with for many algorithms.\n",
      "\n",
      "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
      "identity of the person pictured; however, with only 10 examples per class, this\n",
      "relatively small dataset is more interesting from an unsupervised or\n",
      "semi-supervised perspective.\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the version available here\n",
      "consists of 64x64 images.\n",
      "\n",
      "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2  2\n",
      "  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4\n",
      "  4  4  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7\n",
      "  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9\n",
      "  9  9  9  9 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11\n",
      " 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14\n",
      " 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16\n",
      " 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 19 19\n",
      " 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21\n",
      " 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\n",
      " 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 26 26 26 26\n",
      " 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28\n",
      " 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 31 31\n",
      " 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33\n",
      " 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35 35\n",
      " 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 38 38 38 38\n",
      " 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)\n",
    "print(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aba56bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##stratified sampling since the dataset size is small \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=40, random_state=42)\n",
    "train_valid_idx, test_idx = next(strat_split.split(dataset.data, dataset.target))\n",
    "\n",
    "X_train_valid = dataset.data[train_valid_idx]\n",
    "y_train_valid = dataset.target[train_valid_idx]\n",
    "X_test = dataset.data[test_idx]\n",
    "y_test = dataset.target[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d79df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=80, random_state=43)\n",
    "train_idx, valid_idx = next(strat_split.split(x_train_valid, y_train_valid))\n",
    "\n",
    "X_train = dataset.data[train_idx]\n",
    "y_train = dataset.target[train_idx]\n",
    "X_valid = dataset.data[valid_idx]\n",
    "y_valid = dataset.target[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "914a4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 4096) (280,)\n",
      "(80, 4096) (80,)\n",
      "(40, 4096) (40,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d1b1ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##dimentionality reduction using PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_valid_reduced = pca.transform(X_valid)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "009aacd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d6d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
